{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from fuzzywuzzy import fuzz\n",
    "import Levenshtein\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zswitten/.pyenv/versions/2.7.12/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Dropout, LSTM, Conv2D, Conv1D, MaxPooling1D, MaxPooling2D, Flatten, ZeroPadding1D\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Hemolysis/Cleaned_hemolytic_data.csv')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df.columns = [c.lower() for c in df.columns]\n",
    "df.sequence = df.sequence.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_toxicities(peptide_row, df, k, min_uncertainty):\n",
    "    sequence = peptide_row.sequence\n",
    "    distances = df[df.uncertainty < min_uncertainty][df.sequence != sequence].sequence.apply(lambda x: Levenshtein.distance(x, sequence))\n",
    "    bestk = df.loc[distances.sort_values().iloc[:k]]\n",
    "    avg_toxicity = np.mean(bestk.log10_hc50)\n",
    "    return avg_toxicity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zswitten/.pyenv/versions/2.7.12/lib/python2.7/site-packages/ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "    bestk = knn_toxicities(row, df, 5, 0.1)\n",
    "    df.at[i, 'bestk'] = bestk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log10_hc50</th>\n",
       "      <th>bestk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log10_hc50</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bestk</th>\n",
       "      <td>0.03919</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            log10_hc50    bestk\n",
       "log10_hc50     1.00000  0.03919\n",
       "bestk          0.03919  1.00000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['log10_hc50', 'bestk']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log10_hc50</th>\n",
       "      <th>bestk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log10_hc50</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bestk</th>\n",
       "      <td>0.035214</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            log10_hc50     bestk\n",
       "log10_hc50    1.000000  0.035214\n",
       "bestk         0.035214  1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.uncertainty < 0.1][['log10_hc50', 'bestk']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log10_hc50</th>\n",
       "      <th>bestk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log10_hc50</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bestk</th>\n",
       "      <td>0.062517</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            log10_hc50     bestk\n",
       "log10_hc50    1.000000  0.062517\n",
       "bestk         0.062517  1.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.uncertainty > 0.1][['log10_hc50', 'bestk']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CNN Architecture from MIC Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARACTER_DICT = set([character for sequence in df.sequence for character in sequence])\n",
    "MAX_SEQUENCE_LENGTH = int(df.sequence.str.len().describe(percentiles=[0.95])['95%'])\n",
    "\n",
    "# Each amino acid its own group\n",
    "character_to_index = {\n",
    "    (character): i\n",
    "    for i, character in enumerate(CHARACTER_DICT)\n",
    "}\n",
    "\n",
    "# Group them together heavily\n",
    "\"\"\"character_to_index = {\n",
    "    ('R', 'K', 'H'): 0,\n",
    "    ('D', 'E'): 1,\n",
    "    ('S', 'T', 'N', 'Q', 'C'): 2,\n",
    "    ('A', 'V', 'I', 'L', 'M', 'F', 'Y', 'W', 'P', 'G'): 3,\n",
    "}\n",
    "\n",
    "# Group them together more sparingly\n",
    "character_to_index = {\n",
    "    ('R'): 0,\n",
    "    ('H'): 1,\n",
    "    ('K'): 2,\n",
    "    ('D', 'E'): 3,\n",
    "    ('S', 'T', 'N', 'Q', 'C'): 4,\n",
    "    ('G', 'P'): 5,\n",
    "    ('A', 'V', 'I', 'L', 'M'): 6,\n",
    "    ('F', 'Y', 'W'): 7,\n",
    "}\"\"\"\n",
    "\n",
    "index2character = {\n",
    "    value: key\n",
    "    for key, value in character_to_index.items()\n",
    "}\n",
    "\n",
    "def sequence_to_vector(sequence):\n",
    "    default = np.zeros([MAX_SEQUENCE_LENGTH, len(character_to_index)])\n",
    "    for i, character in enumerate(sequence[:MAX_SEQUENCE_LENGTH]):\n",
    "        default[i][character_to_index[character]] = 1\n",
    "    return default\n",
    "\n",
    "def row_to_vector(row, shuffle_sequence=False):\n",
    "    sequence = list(row['sequence'])\n",
    "    if shuffle_sequence:\n",
    "        random.shuffle(sequence)\n",
    "    return sequence_to_vector(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "SHUFFLE_SEQUENCE = False\n",
    "for row in df.iterrows():\n",
    "    vectors.append(row_to_vector(row[1], shuffle_sequence=SHUFFLE_SEQUENCE))\n",
    "\n",
    "vectors = np.array(vectors)\n",
    "\n",
    "labels = np.array(df.log10_hc50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test_splits(\n",
    "        vectors, labels,\n",
    "        extra_training_vectors=[], extra_training_labels=[], extra_sample_weights=[],\n",
    "        cutoff=0.85\n",
    "):\n",
    "    cutoff = int(cutoff * len(labels))\n",
    "    idx = range(len(vectors))\n",
    "    random.shuffle(idx)\n",
    "    reordered_vectors = vectors[idx]\n",
    "    reordered_labels = labels[idx]\n",
    "    reordered_sample_weights = sample_weights[idx]\n",
    "    if len(extra_training_vectors) > 0:\n",
    "        train_x = np.concatenate((reordered_vectors[:cutoff], extra_training_vectors))\n",
    "        train_y = np.concatenate((reordered_labels[:cutoff], extra_training_labels))\n",
    "        train_sample_weights = np.concatenate((reordered_sample_weights[:cutoff], pa_sample_weights))\n",
    "    else:\n",
    "        train_x = reordered_vectors[:cutoff]\n",
    "        train_y = reordered_labels[:cutoff]\n",
    "        train_sample_weights = reordered_sample_weights[:cutoff]\n",
    "    test_x = reordered_vectors[cutoff:]\n",
    "    test_y = reordered_labels[cutoff:]\n",
    "    return train_x, train_y, test_x, test_y, train_sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional NN\n",
    "def conv_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(ZeroPadding1D(\n",
    "        5, input_shape = (MAX_SEQUENCE_LENGTH, len(character_to_index))\n",
    "    ))\n",
    "    model.add(Conv1D(\n",
    "        64,\n",
    "        kernel_size = 5,\n",
    "        strides = 1,\n",
    "        activation = 'relu',\n",
    "        #input_shape = (MAX_SEQUENCE_LENGTH, len(character_to_index) + 1)\n",
    "    ))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(64, 5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    #model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1170/1170 [==============================] - 1s 511us/step - loss: 1.5147\n",
      "Epoch 2/100\n",
      "1170/1170 [==============================] - 0s 160us/step - loss: 0.6160\n",
      "Epoch 3/100\n",
      "1170/1170 [==============================] - 0s 158us/step - loss: 0.5672\n",
      "Epoch 4/100\n",
      "1170/1170 [==============================] - 0s 157us/step - loss: 0.4749\n",
      "Epoch 5/100\n",
      "1170/1170 [==============================] - 0s 157us/step - loss: 0.4389\n",
      "Epoch 6/100\n",
      "1170/1170 [==============================] - 0s 155us/step - loss: 0.4280\n",
      "Epoch 7/100\n",
      "1170/1170 [==============================] - 0s 159us/step - loss: 0.3891\n",
      "Epoch 8/100\n",
      "1170/1170 [==============================] - 0s 154us/step - loss: 0.3734\n",
      "Epoch 9/100\n",
      "1170/1170 [==============================] - 0s 174us/step - loss: 0.3318\n",
      "Epoch 10/100\n",
      "1170/1170 [==============================] - 0s 162us/step - loss: 0.3267\n",
      "Epoch 11/100\n",
      "1170/1170 [==============================] - 0s 157us/step - loss: 0.2892\n",
      "Epoch 12/100\n",
      "1170/1170 [==============================] - 0s 155us/step - loss: 0.2913\n",
      "Epoch 13/100\n",
      "1170/1170 [==============================] - 0s 163us/step - loss: 0.3027\n",
      "Epoch 14/100\n",
      "1170/1170 [==============================] - 0s 160us/step - loss: 0.2736\n",
      "Epoch 15/100\n",
      "1170/1170 [==============================] - 0s 159us/step - loss: 0.2309\n",
      "Epoch 16/100\n",
      "1170/1170 [==============================] - 0s 167us/step - loss: 0.2229\n",
      "Epoch 17/100\n",
      "1170/1170 [==============================] - 0s 165us/step - loss: 0.2144\n",
      "Epoch 18/100\n",
      "1170/1170 [==============================] - 0s 155us/step - loss: 0.2302\n",
      "Epoch 19/100\n",
      "1170/1170 [==============================] - 0s 154us/step - loss: 0.1993\n",
      "Epoch 20/100\n",
      "1170/1170 [==============================] - 0s 158us/step - loss: 0.2072\n",
      "Epoch 21/100\n",
      "1170/1170 [==============================] - 0s 157us/step - loss: 0.1975\n",
      "Epoch 22/100\n",
      "1170/1170 [==============================] - 0s 155us/step - loss: 0.1824\n",
      "Epoch 23/100\n",
      "1170/1170 [==============================] - 0s 156us/step - loss: 0.1855\n",
      "Epoch 24/100\n",
      "1170/1170 [==============================] - 0s 171us/step - loss: 0.1711\n",
      "Epoch 25/100\n",
      "1170/1170 [==============================] - 0s 163us/step - loss: 0.1687\n",
      "Epoch 26/100\n",
      "1170/1170 [==============================] - 0s 165us/step - loss: 0.1660\n",
      "Epoch 27/100\n",
      "1170/1170 [==============================] - 0s 155us/step - loss: 0.1744\n",
      "Epoch 28/100\n",
      "1170/1170 [==============================] - 0s 157us/step - loss: 0.1587\n",
      "Epoch 29/100\n",
      "1170/1170 [==============================] - 0s 168us/step - loss: 0.1600\n",
      "Epoch 30/100\n",
      "1170/1170 [==============================] - 0s 170us/step - loss: 0.1463\n",
      "Epoch 31/100\n",
      "1170/1170 [==============================] - 0s 158us/step - loss: 0.1598\n",
      "Epoch 32/100\n",
      "1170/1170 [==============================] - 0s 158us/step - loss: 0.1528\n",
      "Epoch 33/100\n",
      "1170/1170 [==============================] - 0s 157us/step - loss: 0.1296\n",
      "Epoch 34/100\n",
      "1170/1170 [==============================] - 0s 153us/step - loss: 0.1259\n",
      "Epoch 35/100\n",
      "1170/1170 [==============================] - 0s 156us/step - loss: 0.1253\n",
      "Epoch 36/100\n",
      "1170/1170 [==============================] - 0s 159us/step - loss: 0.1275\n",
      "Epoch 37/100\n",
      "1170/1170 [==============================] - 0s 154us/step - loss: 0.1316\n",
      "Epoch 38/100\n",
      "1170/1170 [==============================] - 0s 156us/step - loss: 0.1333\n",
      "Epoch 39/100\n",
      "1170/1170 [==============================] - 0s 162us/step - loss: 0.1307\n",
      "Epoch 40/100\n",
      "1170/1170 [==============================] - 0s 205us/step - loss: 0.1461\n",
      "Epoch 41/100\n",
      "1170/1170 [==============================] - 0s 222us/step - loss: 0.1231\n",
      "Epoch 42/100\n",
      "1170/1170 [==============================] - 0s 228us/step - loss: 0.1168\n",
      "Epoch 43/100\n",
      "1170/1170 [==============================] - 0s 187us/step - loss: 0.1237\n",
      "Epoch 44/100\n",
      "1170/1170 [==============================] - 0s 148us/step - loss: 0.1088\n",
      "Epoch 45/100\n",
      "1170/1170 [==============================] - 0s 148us/step - loss: 0.1210\n",
      "Epoch 46/100\n",
      "1170/1170 [==============================] - 0s 163us/step - loss: 0.1191\n",
      "Epoch 47/100\n",
      "1170/1170 [==============================] - 0s 239us/step - loss: 0.1157\n",
      "Epoch 48/100\n",
      "1170/1170 [==============================] - 0s 215us/step - loss: 0.1088\n",
      "Epoch 49/100\n",
      "1170/1170 [==============================] - 0s 179us/step - loss: 0.1165\n",
      "Epoch 50/100\n",
      "1170/1170 [==============================] - 0s 213us/step - loss: 0.1051\n",
      "Epoch 51/100\n",
      "1170/1170 [==============================] - 0s 159us/step - loss: 0.1017\n",
      "Epoch 52/100\n",
      "1170/1170 [==============================] - 0s 152us/step - loss: 0.1030\n",
      "Epoch 53/100\n",
      "1170/1170 [==============================] - 0s 176us/step - loss: 0.1010\n",
      "Epoch 54/100\n",
      "1170/1170 [==============================] - 0s 194us/step - loss: 0.1020\n",
      "Epoch 55/100\n",
      "1170/1170 [==============================] - 0s 170us/step - loss: 0.0914\n",
      "Epoch 56/100\n",
      "1170/1170 [==============================] - 0s 156us/step - loss: 0.0993\n",
      "Epoch 57/100\n",
      "1170/1170 [==============================] - 0s 153us/step - loss: 0.0899\n",
      "Epoch 58/100\n",
      "1170/1170 [==============================] - 0s 151us/step - loss: 0.0946\n",
      "Epoch 59/100\n",
      "1170/1170 [==============================] - 0s 172us/step - loss: 0.0902\n",
      "Epoch 60/100\n",
      "1170/1170 [==============================] - 0s 190us/step - loss: 0.0931\n",
      "Epoch 61/100\n",
      "1170/1170 [==============================] - 0s 184us/step - loss: 0.0936\n",
      "Epoch 62/100\n",
      "1170/1170 [==============================] - 0s 161us/step - loss: 0.0858\n",
      "Epoch 63/100\n",
      "1170/1170 [==============================] - 0s 150us/step - loss: 0.0912\n",
      "Epoch 64/100\n",
      "1170/1170 [==============================] - 0s 149us/step - loss: 0.0859\n",
      "Epoch 65/100\n",
      "1170/1170 [==============================] - 0s 203us/step - loss: 0.0875\n",
      "Epoch 66/100\n",
      "1170/1170 [==============================] - 0s 164us/step - loss: 0.0882\n",
      "Epoch 67/100\n",
      "1170/1170 [==============================] - 0s 201us/step - loss: 0.0847\n",
      "Epoch 68/100\n",
      "1170/1170 [==============================] - 0s 202us/step - loss: 0.0790\n",
      "Epoch 69/100\n",
      "1170/1170 [==============================] - 0s 175us/step - loss: 0.0777\n",
      "Epoch 70/100\n",
      "1170/1170 [==============================] - 0s 230us/step - loss: 0.0930\n",
      "Epoch 71/100\n",
      "1170/1170 [==============================] - 0s 216us/step - loss: 0.0796\n",
      "Epoch 72/100\n",
      "1170/1170 [==============================] - 0s 205us/step - loss: 0.0761\n",
      "Epoch 73/100\n",
      " 920/1170 [======================>.......] - ETA: 0s - loss: 0.0815"
     ]
    }
   ],
   "source": [
    "convmodel = conv_model()\n",
    "train_x, train_y, test_x, test_y, _ = generate_train_test_splits(vectors, labels)\n",
    "convmodel.fit(train_x, train_y, batch_size=40, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN test error, MSE of log10_hc50\n",
      "207/207 [==============================] - 0s 79us/step\n",
      "0.4875335242725225\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN test error, MSE of log10_hc50\")\n",
    "print(convmodel.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnn_preds</th>\n",
       "      <th>test_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cnn_preds</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.548227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_y</th>\n",
       "      <td>0.548227</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cnn_preds    test_y\n",
       "cnn_preds   1.000000  0.548227\n",
       "test_y      0.548227  1.000000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_preds = convmodel.predict(test_x)\n",
    "cnn_preds = cnn_preds.reshape((cnn_preds.shape[0]))\n",
    "pd.DataFrame({'cnn_preds': cnn_preds, 'test_y': test_y}).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
